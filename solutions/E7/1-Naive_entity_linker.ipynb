{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Entity Linker\n",
    "\n",
    "In this exercise, you'll need to create the simplest possible entity linker, which recognizes city names in text and links those to the corresponding Wikipedia page.\n",
    "\n",
    "Since we aim for a minimalistic solution, we won't be dealing with the problem of disambiguation explicitly.  Instead, we construct a surface form dictionary such that each mention is mapped to a single entity.  Then, the task boils down to (i) the construction of the surface form dictionary, and (ii) the recognition of mentions (dictionary keys) in the text.\n",
    "\n",
    "We use part of the Wikipedia URL after the last slash to uniquely represent entities, i.e., as `entity_ID`.\n",
    "\n",
    "The goal is to have a minimalistic working solution first, then expand it iteratively.\n",
    "- For the minimal version, consider only capitals in Europe. (All those cities should have unique names.)\n",
    "- Expand the list of cities by considering other Wikipedia lists and/or DBpedia properties. At this point, we don't deal with ambiguity; if a city name has already been added to the surface form dictionary, we ignore it.\n",
    "- Finally, we resolve ambiguity by considering the more popular sense of the entity. Since we don't have link information easily available, we'll use the population of the city as a proxy. That is, if there are multiple cities with the same name, keep the one in the surface form dictionary with the highest population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "import re\n",
    "import string\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Obtain a list of cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect potential city names from Wikipedia categories. Note that not all the pages will be actual cities. We'll filter those later in the surface form dictionary creation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have the Wikipedia API, install it using `conda install -c conda-forge wikipedia-api` or `pip install wikipedia-api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities(seed_cats: List[str]) -> List[str]:\n",
    "    \"\"\"Returns a list of cities represented by their entity_IDs.\n",
    "    \n",
    "    Args:\n",
    "        seed_cats: Names of wikipedia categories that may be used for collecting cities.\n",
    "    \n",
    "    Returns:\n",
    "        List of entity_IDs.\n",
    "    \"\"\"\n",
    "    wiki_wiki = wikipediaapi.Wikipedia(\"en\")\n",
    "    cities = []\n",
    "    for seed_cat in seed_cats:\n",
    "        cat = wiki_wiki.page(f\"Category:{seed_cat}\")\n",
    "        for c in cat.categorymembers.values():\n",
    "            if c.ns != wikipediaapi.Namespace.CATEGORY:\n",
    "                cities.append(c.title)\n",
    "    \n",
    "    return cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = get_cities([\"Capitals_in_Europe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['European Capital of Culture',\n",
       " 'European Youth Capital',\n",
       " 'Amsterdam',\n",
       " 'Andorra la Vella',\n",
       " 'Athens',\n",
       " 'Belgrade',\n",
       " 'Berlin',\n",
       " 'Bern',\n",
       " 'Bratislava',\n",
       " 'City of Brussels']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a sample.\n",
    "cities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a surface form dictionary\n",
    "\n",
    "We create a dictionary that maps surface forms to entity_IDs (single entity_ID per surface form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sf_dict(cities: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Creates a surface form dictionary for a given list of cities.\n",
    "    \n",
    "    Args:\n",
    "        cities: List of entity_IDs of cities.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with mention as key and entity_ID as value.\n",
    "    \"\"\"\n",
    "    sf_dict = {}\n",
    "    for city in cities:\n",
    "        sf_dict[city] = city.replace(\" \", \"_\")\n",
    "    return sf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_dict = create_sf_dict(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check surface form dictionary\n",
    "#sf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Perform entity linking\n",
    "\n",
    "Perform entity linking with the help of the surface form dictionary. In case of overlapping mentions, link the longer one (e.g., if both \"Amsterdam\" and \"New Amsterdam\" are present in the surface form dictionary, then the mention \"New Amsterdam\" should be linked to the latter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linking(input_text: str, sf_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"Annotates a given input text with entities.\n",
    "    \n",
    "    Args:\n",
    "        input_text: Input text.\n",
    "        sf_dict: Surface form dictionary, mapping each mention to a canonical entity.\n",
    "    \n",
    "    Returns:\n",
    "        Annotated text where linked entity mentions are marked up as `[mention](entity_ID)`.\n",
    "    \"\"\"    \n",
    "    annotated_text = input_text\n",
    "    # Remove punctuation.\n",
    "    preprocessed_text = input_text.translate(str.maketrans(\"\", \"\", string.punctuation)) \n",
    "    tokenized_text = preprocessed_text.split()\n",
    "    for n in range(5, 0, -1):  # Assumes city names are at most 5 tokens long\n",
    "        for i in range(0, len(tokenized_text) - n + 1):\n",
    "            ngram = \" \".join(tokenized_text[i:i+n])\n",
    "            if ngram in sf_dict:\n",
    "                annotated_text = annotated_text.replace(ngram, f\"[{ngram}]({sf_dict[ngram]})\")\n",
    "                # Remove tokens so that they cannot be linked to other entities.\n",
    "                tokenized_text[i:i+n+1] = [\"\"] * n \n",
    "        \n",
    "    return annotated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....                                                                              [100%]\n",
      "5 passed in 0.03s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "SF_DICT_TEST = {\n",
    "    \"London\": \"London\",\n",
    "    \"Luxembourg\": \"Luxembourg_City\",\n",
    "    \"Luxembourg City\": \"Luxembourg_City\",\n",
    "    \"Amsterdam\": \"Amsterdam\",\n",
    "    \"New Amsterdam\": \"New_Amsterdam\",\n",
    "}\n",
    "\n",
    "@pytest.mark.parametrize(\"input_text,correct_value\", [\n",
    "    (\"no city mentioned\", \"no city mentioned\"),  # no entity mentioned \n",
    "    (\"This is an example mention of Amsterdam.\",  # single entity\n",
    "     \"This is an example mention of [Amsterdam](Amsterdam).\"),\n",
    "    (\"Luxembourg City is located in ...\",  # multi-term city name\n",
    "     \"[Luxembourg City](Luxembourg_City) is located in ...\"),\n",
    "    (\"London is a popular city name\",  # cities sharing the same name\n",
    "     \"[London](London) is a popular city name\"),\n",
    "    (\"Have you ever been to New Amsterdam?\",  # overlapping entity mentions\n",
    "     \"Have you ever been to [New Amsterdam](New_Amsterdam)?\")\n",
    "])\n",
    "def test_perform_linking(input_text, correct_value):\n",
    "    assert perform_linking(input_text, SF_DICT_TEST) == correct_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Render links\n",
    "\n",
    "Assuming that you have added entity annotations to the input text in `[mention](entity_ID)` format, render that text as clickable links.  Essentially, you'll need to replace `[mention](entity_ID)` with `<a href=\"https://en.wikipedia.org/wiki/{entity_ID}\">{mention}</a>` (where `{}` indicates variable placeholders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example mention of [Amsterdam](Amsterdam).\n"
     ]
    }
   ],
   "source": [
    "def render_links(annotated_text: str) -> str:\n",
    "    # TODO\n",
    "    return annotated_text\n",
    "\n",
    "annotated_text = perform_linking(\"This is an example mention of Amsterdam.\", sf_dict)\n",
    "print(render_links(annotated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing an automated test, we will simply look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', 'mention', 'of', 'Amsterdam']\n",
      "5\n",
      "This is an example mention\n",
      "is an example mention of\n",
      "an example mention of Amsterdam\n",
      "4\n",
      "This is an example\n",
      "is an example mention\n",
      "an example mention of\n",
      "example mention of Amsterdam\n",
      "3\n",
      "This is an\n",
      "is an example\n",
      "an example mention\n",
      "example mention of\n",
      "mention of Amsterdam\n",
      "2\n",
      "This is\n",
      "is an\n",
      "an example\n",
      "example mention\n",
      "mention of\n",
      "of Amsterdam\n",
      "1\n",
      "This\n",
      "is\n",
      "an\n",
      "example\n",
      "mention\n",
      "of\n",
      "Amsterdam\n",
      "This is an example mention of [Amsterdam]<a href=\u0001>Amsterdam<a href=\u0001><a href=\u0001>\n"
     ]
    }
   ],
   "source": [
    "annotated_text = perform_linking(\"This is an example mention of Amsterdam.\", sf_dict)\n",
    "print(render_links(annotated_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
