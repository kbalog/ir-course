{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch\n",
    "\n",
    "Run this example to index and search a toy-sized collection of documents using Elasticsearch.  There is nothing for you to add/complete here, it's just to make sure you're all set for the next exercise.\n",
    "\n",
    "Before starting, make sure that you've \n",
    "\n",
    "1. Downloaded and started Elasticsearch\n",
    "1. Installed the `elasticsearch` Python package\n",
    "  - It's part of the standard Anaconda distribution; otherwise, you can run `conda install elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"toy_index\"  # the name of the index\n",
    "\n",
    "INDEX_SETTINGS = {  # single shard with a single replica\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"number_of_shards\" : 1,\n",
    "            \"number_of_replicas\" : 1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of documents is given here as a Python dictionary. Each document has two fields: title and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS = {\n",
    "    1: {\"title\": \"Rap God\",\n",
    "        \"content\": \"gonna, gonna, Look, I was gonna go easy on you and not to hurt your feelings\"\n",
    "        },\n",
    "    2: {\"title\": \"Lose Yourself\",\n",
    "        \"content\": \"Yo, if you could just, for one minute Or one split second in time, forget everything Everything that bothers you, or your problems Everything, and follow me\"\n",
    "        },\n",
    "    3: {\"title\": \"Love The Way You Lie\",\n",
    "        \"content\": \"Just gonna stand there and watch me burn But that's alright, because I like the way it hurts\"\n",
    "        },\n",
    "    4: {\"title\": \"The Monster\",\n",
    "        \"content\": [\"gonna gonna I'm friends with the monster\", \"That's under my bed Get along with the voices inside of my head\"]\n",
    "        },\n",
    "    5: {\"title\": \"Beautiful\",\n",
    "        \"content\": \"Lately I've been hard to reach I've been too long on my own Everybody has a private world Where they can be alone\"\n",
    "        }\n",
    "}  # Eminem rulez ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Elasticsearch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if service is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'k122-129.ux.uis.no',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': '0LQmPetvQsacAJ8SLmPybA',\n",
       " 'version': {'number': '7.9.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'tar',\n",
       "  'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e',\n",
       "  'build_date': '2020-09-23T00:45:33.626720Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.6.2',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the index exists, we delete it (normally, you don't want to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if es.indices.exists(INDEX_NAME):\n",
    "    es.indices.delete(index=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the number of shards and replicas to be used for each index when it's created. (We use a single shard instead of the default 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'toy_index'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id, doc in DOCS.items():\n",
    "    es.index(index=INDEX_NAME, doc_type=\"_doc\", id=doc_id, body=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what has been indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the contents of doc #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = es.get(index=INDEX_NAME, id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '3',\n",
      " '_index': 'toy_index',\n",
      " '_primary_term': 1,\n",
      " '_seq_no': 2,\n",
      " '_source': {'content': \"Just gonna stand there and watch me burn But that's \"\n",
      "                        'alright, because I like the way it hurts',\n",
      "             'title': 'Love The Way You Lie'},\n",
      " '_type': '_doc',\n",
      " '_version': 1,\n",
      " 'found': True}\n"
     ]
    }
   ],
   "source": [
    "pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the term vector for doc #3.\n",
    "\n",
    "`termvectors` returns information and statistics on terms in the fields of a particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = es.termvectors(index=INDEX_NAME, doc_type=\"_doc\", id=3, fields=\"title,content\", term_statistics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '3',\n",
      " '_index': 'toy_index',\n",
      " '_type': '_doc',\n",
      " '_version': 1,\n",
      " 'found': True,\n",
      " 'term_vectors': {'content': {'field_statistics': {'doc_count': 5,\n",
      "                                                   'sum_doc_freq': 91,\n",
      "                                                   'sum_ttf': 104},\n",
      "                              'terms': {'alright': {'doc_freq': 1,\n",
      "                                                    'term_freq': 1,\n",
      "                                                    'tokens': [{'end_offset': 59,\n",
      "                                                                'position': 10,\n",
      "                                                                'start_offset': 52}],\n",
      "                                                    'ttf': 1},\n",
      "                                        'and': {'doc_freq': 3,\n",
      "                                                'term_freq': 1,\n",
      "                                                'tokens': [{'end_offset': 26,\n",
      "                                                            'position': 4,\n",
      "                                                            'start_offset': 23}],\n",
      "                                                'ttf': 3},\n",
      "                                        'because': {'doc_freq': 1,\n",
      "                                                    'term_freq': 1,\n",
      "                                                    'tokens': [{'end_offset': 68,\n",
      "                                                                'position': 11,\n",
      "                                                                'start_offset': 61}],\n",
      "                                                    'ttf': 1},\n",
      "                                        'burn': {'doc_freq': 1,\n",
      "                                                 'term_freq': 1,\n",
      "                                                 'tokens': [{'end_offset': 40,\n",
      "                                                             'position': 7,\n",
      "                                                             'start_offset': 36}],\n",
      "                                                 'ttf': 1},\n",
      "                                        'but': {'doc_freq': 1,\n",
      "                                                'term_freq': 1,\n",
      "                                                'tokens': [{'end_offset': 44,\n",
      "                                                            'position': 8,\n",
      "                                                            'start_offset': 41}],\n",
      "                                                'ttf': 1},\n",
      "                                        'gonna': {'doc_freq': 3,\n",
      "                                                  'term_freq': 1,\n",
      "                                                  'tokens': [{'end_offset': 10,\n",
      "                                                              'position': 1,\n",
      "                                                              'start_offset': 5}],\n",
      "                                                  'ttf': 6},\n",
      "                                        'hurts': {'doc_freq': 1,\n",
      "                                                  'term_freq': 1,\n",
      "                                                  'tokens': [{'end_offset': 92,\n",
      "                                                              'position': 17,\n",
      "                                                              'start_offset': 87}],\n",
      "                                                  'ttf': 1},\n",
      "                                        'i': {'doc_freq': 2,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'end_offset': 70,\n",
      "                                                          'position': 12,\n",
      "                                                          'start_offset': 69}],\n",
      "                                              'ttf': 2},\n",
      "                                        'it': {'doc_freq': 1,\n",
      "                                               'term_freq': 1,\n",
      "                                               'tokens': [{'end_offset': 86,\n",
      "                                                           'position': 16,\n",
      "                                                           'start_offset': 84}],\n",
      "                                               'ttf': 1},\n",
      "                                        'just': {'doc_freq': 2,\n",
      "                                                 'term_freq': 1,\n",
      "                                                 'tokens': [{'end_offset': 4,\n",
      "                                                             'position': 0,\n",
      "                                                             'start_offset': 0}],\n",
      "                                                 'ttf': 2},\n",
      "                                        'like': {'doc_freq': 1,\n",
      "                                                 'term_freq': 1,\n",
      "                                                 'tokens': [{'end_offset': 75,\n",
      "                                                             'position': 13,\n",
      "                                                             'start_offset': 71}],\n",
      "                                                 'ttf': 1},\n",
      "                                        'me': {'doc_freq': 2,\n",
      "                                               'term_freq': 1,\n",
      "                                               'tokens': [{'end_offset': 35,\n",
      "                                                           'position': 6,\n",
      "                                                           'start_offset': 33}],\n",
      "                                               'ttf': 2},\n",
      "                                        'stand': {'doc_freq': 1,\n",
      "                                                  'term_freq': 1,\n",
      "                                                  'tokens': [{'end_offset': 16,\n",
      "                                                              'position': 2,\n",
      "                                                              'start_offset': 11}],\n",
      "                                                  'ttf': 1},\n",
      "                                        \"that's\": {'doc_freq': 2,\n",
      "                                                   'term_freq': 1,\n",
      "                                                   'tokens': [{'end_offset': 51,\n",
      "                                                               'position': 9,\n",
      "                                                               'start_offset': 45}],\n",
      "                                                   'ttf': 2},\n",
      "                                        'the': {'doc_freq': 2,\n",
      "                                                'term_freq': 1,\n",
      "                                                'tokens': [{'end_offset': 79,\n",
      "                                                            'position': 14,\n",
      "                                                            'start_offset': 76}],\n",
      "                                                'ttf': 3},\n",
      "                                        'there': {'doc_freq': 1,\n",
      "                                                  'term_freq': 1,\n",
      "                                                  'tokens': [{'end_offset': 22,\n",
      "                                                              'position': 3,\n",
      "                                                              'start_offset': 17}],\n",
      "                                                  'ttf': 1},\n",
      "                                        'watch': {'doc_freq': 1,\n",
      "                                                  'term_freq': 1,\n",
      "                                                  'tokens': [{'end_offset': 32,\n",
      "                                                              'position': 5,\n",
      "                                                              'start_offset': 27}],\n",
      "                                                  'ttf': 1},\n",
      "                                        'way': {'doc_freq': 1,\n",
      "                                                'term_freq': 1,\n",
      "                                                'tokens': [{'end_offset': 83,\n",
      "                                                            'position': 15,\n",
      "                                                            'start_offset': 80}],\n",
      "                                                'ttf': 1}}},\n",
      "                  'title': {'field_statistics': {'doc_count': 5,\n",
      "                                                 'sum_doc_freq': 12,\n",
      "                                                 'sum_ttf': 12},\n",
      "                            'terms': {'lie': {'doc_freq': 1,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'end_offset': 20,\n",
      "                                                          'position': 4,\n",
      "                                                          'start_offset': 17}],\n",
      "                                              'ttf': 1},\n",
      "                                      'love': {'doc_freq': 1,\n",
      "                                               'term_freq': 1,\n",
      "                                               'tokens': [{'end_offset': 4,\n",
      "                                                           'position': 0,\n",
      "                                                           'start_offset': 0}],\n",
      "                                               'ttf': 1},\n",
      "                                      'the': {'doc_freq': 2,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'end_offset': 8,\n",
      "                                                          'position': 1,\n",
      "                                                          'start_offset': 5}],\n",
      "                                              'ttf': 2},\n",
      "                                      'way': {'doc_freq': 1,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'end_offset': 12,\n",
      "                                                          'position': 2,\n",
      "                                                          'start_offset': 9}],\n",
      "                                              'ttf': 1},\n",
      "                                      'you': {'doc_freq': 1,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'end_offset': 16,\n",
      "                                                          'position': 3,\n",
      "                                                          'start_offset': 13}],\n",
      "                                              'ttf': 1}}}},\n",
      " 'took': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint(tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the returned values\n",
    "  * `[{field}]['field_statistics']`: \n",
    "    - `doc_count`: how many documents contain this field\n",
    "    - `sum_ttf`: the sum of all term frequencies in this field\n",
    "  * `[{field}][{term}]`:\n",
    "    - `doc_freq`: how many document contain this term\n",
    "    - `term_freq`: frequency (number of occurrences) of the term in this document field\n",
    "    - `ttf`: total term frequency, i.e., number of occurrences of the term in this field in all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Elasticsearch splits indices into multiple shards (by default: 5). This means that when you ask for term statistics, these are computed by shard. In case of a large collection, this is typically not an issue as the statistics become \"normalized\" across the different shards and the differences are negligible. For smaller collections that fit on a single disk, you may set the number of shards to 1 to avoid this issue alltogether (like we've done in this example in `INDEX_SETTINGS`).\n",
    "\n",
    "Check the following documents for further information:\n",
    "  - https://www.elastic.co/guide/en/elasticsearch/reference/6.2/_basic_concepts.html\n",
    "  - https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"rap monster\"\n",
    "res = es.search(index=INDEX_NAME, q=query, _source=False, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print full response (`hits` holds the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_shards': {'failed': 0, 'skipped': 0, 'successful': 1, 'total': 1},\n",
      " 'hits': {'hits': [],\n",
      "          'max_score': None,\n",
      "          'total': {'relation': 'eq', 'value': 0}},\n",
      " 'timed_out': False,\n",
      " 'took': 2}\n"
     ]
    }
   ],
   "source": [
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print only search results (ranked list of docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(\"Doc ID: %3r  Score: %5.2f\" % (hit[\"_id\"], hit[\"_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch query language\n",
    "\n",
    "Elasticsearch supports structured queries based on its own [DSL query language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html).\n",
    "\n",
    "Mind that certain queries expect analyzed query terms (e.g., [term queries](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html)), while other query types (e.g., [match](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html)) perform analysis as part of the processing. Make sure you check the respective documentation carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a second toy index with position information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME2 = \"toy_index2\"  \n",
    "\n",
    "INDEX_SETTINGS2 = {\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"number_of_shards\" : 1,\n",
    "            \"number_of_replicas\" : 1\n",
    "        },\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"my_english_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"stopwords\": \"_english_\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"english_stop\",\n",
    "                        \"filter_english_minimal\"\n",
    "                    ]                \n",
    "                }\n",
    "            },\n",
    "            \"filter\" : {\n",
    "                \"filter_english_minimal\" : {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"name\": \"minimal_english\"\n",
    "                },\n",
    "                \"english_stop\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"term_vector\": \"with_positions\",\n",
    "                \"analyzer\": \"my_english_analyzer\"\n",
    "            },\n",
    "            \"content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"term_vector\": \"with_positions\",\n",
    "                \"analyzer\": \"my_english_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'toy_index2'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if es.indices.exists(INDEX_NAME2):\n",
    "    es.indices.delete(index=INDEX_NAME2)\n",
    "    \n",
    "es.indices.create(index=INDEX_NAME2, body=INDEX_SETTINGS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id, doc in DOCS.items():\n",
    "    es.index(index=INDEX_NAME2, doc_type=\"_doc\", id=doc_id, body=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that term position information has been added to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '3',\n",
      " '_index': 'toy_index2',\n",
      " '_type': '_doc',\n",
      " '_version': 1,\n",
      " 'found': True,\n",
      " 'term_vectors': {'title': {'field_statistics': {'doc_count': 5,\n",
      "                                                 'sum_doc_freq': 10,\n",
      "                                                 'sum_ttf': 10},\n",
      "                            'terms': {'lie': {'doc_freq': 1,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'position': 4}],\n",
      "                                              'ttf': 1},\n",
      "                                      'love': {'doc_freq': 1,\n",
      "                                               'term_freq': 1,\n",
      "                                               'tokens': [{'position': 0}],\n",
      "                                               'ttf': 1},\n",
      "                                      'way': {'doc_freq': 1,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'position': 2}],\n",
      "                                              'ttf': 1},\n",
      "                                      'you': {'doc_freq': 1,\n",
      "                                              'term_freq': 1,\n",
      "                                              'tokens': [{'position': 3}],\n",
      "                                              'ttf': 1}}}},\n",
      " 'took': 256}\n"
     ]
    }
   ],
   "source": [
    "tv = es.termvectors(index=INDEX_NAME2, doc_type=\"_doc\", id=3, fields=\"title\", term_statistics=True)\n",
    "\n",
    "pprint(tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for documents that must match a [boolean combination](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html) of multiple terms (in any order).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_shards': {'failed': 0, 'skipped': 0, 'successful': 1, 'total': 1},\n",
      " 'hits': {'hits': [],\n",
      "          'max_score': None,\n",
      "          'total': {'relation': 'eq', 'value': 0}},\n",
      " 'timed_out': False,\n",
      " 'took': 1}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"match\": {\"content\": \"gonna\"}}, \n",
    "            {\"match\": {\"content\": \"monster\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=INDEX_NAME2, body={\"query\": query})\n",
    "\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for documents that match an [extract phrase](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase.html) (terms in that exact order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_shards': {'failed': 0, 'skipped': 0, 'successful': 1, 'total': 1},\n",
      " 'hits': {'hits': [{'_id': '2',\n",
      "                    '_index': 'toy_index2',\n",
      "                    '_score': 1.7076306,\n",
      "                    '_source': {'content': 'Yo, if you could just, for one '\n",
      "                                           'minute Or one split second in '\n",
      "                                           'time, forget everything Everything '\n",
      "                                           'that bothers you, or your problems '\n",
      "                                           'Everything, and follow me',\n",
      "                                'title': 'Lose Yourself'},\n",
      "                    '_type': '_doc'}],\n",
      "          'max_score': 1.7076306,\n",
      "          'total': {'relation': 'eq', 'value': 1}},\n",
      " 'timed_out': False,\n",
      " 'took': 2}\n"
     ]
    }
   ],
   "source": [
    "query = {\"match_phrase\": {\"content\": \"split second\"}}\n",
    "\n",
    "res = es.search(index=INDEX_NAME2, body={'query': query})\n",
    "\n",
    "pprint(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
