# L1: Text classification and preprocessing

The first lecture discusses the problem of text classification. It is assumed that you're familiar with the problem of classification (or categorization) from prior courses (machine learning and data mining). In this course, our focus will be on working with textual data. Hence, we cover some basic properties of text as well as basic preprocessing steps. The part on evaluation should be familiar from previous courses; it is nevertheless included as a refresher, given the course's strong emphasis on sound evaluation methodologies and measures.

## Lecture videos and slides

| L1-1 | Text classification | [video lecture](https://youtu.be/3LMjRlwZzSA) | [slides](https://speakerdeck.com/kbalog/information-retrieval-and-text-mining-2020-text-classification) |
| L1-2 | Text preprocessing | [video lecture](https://youtu.be/IuBvlOuD3js) | [slides](https://speakerdeck.com/kbalog/information-retrieval-and-text-mining-2020-text-preprocessing)
| L1-3 | Naive Bayes classifier | [video lecture](https://youtu.be/EIXxvno9hLU) | [slides](https://speakerdeck.com/kbalog/information-retrieval-and-text-mining-2020-text-classification-naive-bayes) |
| L1-4 | Text classification evaluation | [video lecture](https://youtu.be/3LdPjTW3F6I) | [slides](https://speakerdeck.com/kbalog/information-retrieval-and-text-mining-2020-text-classification-evaluation) |

## Reading

  * Zhai & Massung: Chapter 15
  * Zhai & Massung: Section 8.1

## Summary

Key concepts in this lecture:

  * Problem of text classification (binary and multiclass variants)
  * Feature-bases text classifiers (bag-of-words representation, document-term matrix)
  * Statistical properties of text (Zipf's law)
  * Term weighting (TF-IDF)
  * Text preprocessing (tokenization, stopwords removal, stemming)
  * Types of stemmers (algorithmic, dictionary-based, hybrid)
  * Naive Bayes classifier
  * Evaluation (confusion matrix, binary/multiclass)
  * Evaluation measures (accuracy, precision, recall, F1, micro- and macro-averaging)
  * Training/test splits, cross-validation
